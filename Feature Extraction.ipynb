{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5cb774-7fa2-4f7f-9a8d-57041f70fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 173s 2us/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load and preprocess an example image\u001b[39;00m\n\u001b[0;32m     11\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your image file\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[0;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_image.jpg'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet data\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Load and preprocess an example image\n",
    "img_path = 'path_to_your_image.jpg'  # Replace with the path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = model.predict(x)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "# Print the top predictions\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de5fcfe7-3ea5-48a3-8c09-16b5258c2d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49705c64-b29d-46eb-a4f3-f3cba1c90e19",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape (2955873701.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    img_path = '\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\data\".jpg'  # Replace with the path to your image file\u001b[0m\n\u001b[1;37m                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet data\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Load and preprocess an example image\n",
    "img_path = '\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\data\".jpg'  # Replace with the path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = model.predict(x)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "# Print the top predictions\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba39bd6-1d62-4c68-895f-2f6c0fb38ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 3us/step\n",
      "1: web_site (0.07)\n",
      "2: digital_clock (0.05)\n",
      "3: nematode (0.04)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet data\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "# You can replace this placeholder image array with your actual image data\n",
    "x = np.random.rand(1, 224, 224, 3)  # Replace with your image array\n",
    "x = preprocess_input(x)\n",
    "\n",
    "predictions = model.predict(x)\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "# Print the top predictions\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f'{i + 1}: {label} ({score:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8f43c0-b482-40e8-953c-9f71738c663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "69197824/94765736 [====================>.........] - ETA: 2:40"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete or corrupted file detected. The auto file hash does not match the provided value of 4d473c1dd8becc155b73f8504c6f6626.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:232\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m         file_name \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    229\u001b[0m             model_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m         file_hash \u001b[38;5;241m=\u001b[39m WEIGHTS_HASHES[model_name][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 232\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m \u001b[43mdata_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBASE_WEIGHTS_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\data_utils.py:362\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fpath) \u001b[38;5;129;01mand\u001b[39;00m file_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validate_file(fpath, file_hash, algorithm\u001b[38;5;241m=\u001b[39mhash_algorithm):\n\u001b[1;32m--> 362\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    363\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncomplete or corrupted file detected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile hash does not match the provided value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m             )\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m untar:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(untar_fpath):\n",
      "\u001b[1;31mValueError\u001b[0m: Incomplete or corrupted file detected. The auto file hash does not match the provided value of 4d473c1dd8becc155b73f8504c6f6626."
     ]
    }
   ],
   "source": [
    "model=ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a691cf-ad26-4717-a0a2-d19f314ebae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 124s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model=ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a517d93-52ba-479a-9659-a8b2d95e067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b986c0-f609-4da1-a550-ade6b882146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 3, 3, 2048)        23587712  \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 2048)              0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23587712 (89.98 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tensorflow.keras.Sequential([\n",
    "    model,\n",
    "    GlobalMaxPooling2D()\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd6099ce-24a2-402e-b18d-431160f7b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18901bc3-4a95-4c28-b5c5-b1a7215ba58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"1636.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcd7f2c7-f1df-45a8-819b-904a5c4c115f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mimg\u001b[49m)\n\u001b[0;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"Frame\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8588b191-89ae-448f-80b3-0c1c7e133fde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load and process your image\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ...\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Display the image using cv2\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mimg\u001b[49m)\n\u001b[0;32m      8\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load and process your image\n",
    "# ...\n",
    "\n",
    "# Display the image using cv2\n",
    "cv2.imshow(\"Frame\", img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd168755-4348-4a1a-ab48-4ed43808ec1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3026469631.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    img_path = 'img_path = 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\data\\\\Apparel\\\\Boys\\\\Images\\\\images_with_product_ids.jpg'\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = 'img_path = 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\data\\\\Apparel\\\\Boys\\\\Images\\\\images_with_product_ids.jpg'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Convert the PIL image to a NumPy array for use with cv2\n",
    "img_cv2 = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the image using cv2\n",
    "cv2.imshow(\"Frame\", img_cv2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5c9cd69-6c85-47b0-b992-df84d5e878b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\data\\\\Apparel\\\\Boys\\\\Images\\\\images_with_product_ids.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image using PIL\u001b[39;00m\n\u001b[0;32m      4\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLenovo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfashionrecm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mApparel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBoys\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages_with_product_ids.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the PIL image to a NumPy array for use with cv2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m img_cv2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(np\u001b[38;5;241m.\u001b[39marray(img), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\data\\\\Apparel\\\\Boys\\\\Images\\\\images_with_product_ids.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = r'C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\data\\Apparel\\Boys\\Images\\images_with_product_ids.jpg'\n",
    "\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Convert the PIL image to a NumPy array for use with cv2\n",
    "img_cv2 = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the image using cv2\n",
    "cv2.imshow(\"Frame\", img_cv2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29f313a3-efd7-4b98-ac86-026b80396ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images_with_product_ids.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image using PIL\u001b[39;00m\n\u001b[0;32m      6\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_with_product_ids.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Assuming the image is in the same directory\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Convert the PIL image to a NumPy array for use with cv2\u001b[39;00m\n\u001b[0;32m     10\u001b[0m img_cv2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(np\u001b[38;5;241m.\u001b[39marray(img), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images_with_product_ids.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = 'images_with_product_ids.jpg'  # Assuming the image is in the same directory\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Convert the PIL image to a NumPy array for use with cv2\n",
    "img_cv2 = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the image using cv2\n",
    "cv2.imshow(\"Frame\", img_cv2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efd16648-97c4-477a-bb73-191daabaaba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '15573.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image using PIL\u001b[39;00m\n\u001b[0;32m      5\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m15573.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the PIL image to a NumPy array\u001b[39;00m\n\u001b[0;32m      9\u001b[0m img_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '15573.jpg'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = \"15573.jpg\"\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Convert the PIL image to a NumPy array\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Display the image using OpenCV\n",
    "cv2.imshow(\"Image\", img_np)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80ca816f-5a1b-4245-840f-75c83e1456b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3703218037.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    img=cv2.imread(\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\data\\Apparel\\Boys\\Images\\images_with_product_ids\")\u001b[0m\n\u001b[1;37m                                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8352488-5b82-4ddc-b4a3-a300e208ad24",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3703218037.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    img=cv2.imread(\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\data\\Apparel\\Boys\\Images\\images_with_product_ids\")\u001b[0m\n\u001b[1;37m                                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"15573.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60f4c0ec-6ba5-4b31-b8ba-227cd276560e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"Frame\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2ac52d-f156-4a28-b2bf-1a673b7b8406",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3703218037.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    img=cv2.imread(\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\data\\Apparel\\Boys\\Images\\images_with_product_ids\")\u001b[0m\n\u001b[1;37m                                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b09525-feeb-46a9-ab89-d060a0807615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"15573.jpg\")\n",
    "\n",
    "if img is not None:\n",
    "    cv2.imwrite(\"saved_image.jpg\", img)\n",
    "    print(\"Image saved successfully.\")\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "\n",
    "# Now you can manually open the \"saved_image.jpg\" file using your system's image viewer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43d02bf9-8b64-44d6-bd78-55a63b92d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "img_path = \"2693.jpg\"\n",
    "if os.path.exists(img_path):\n",
    "    print(\"Image file exists.\")\n",
    "else:\n",
    "    print(\"Image file does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "685a8d44-b0d4-4443-981c-9711e54a8ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\Scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55597614-a84a-4301-9501-7baa3ebeae06",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2693.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img_path = \"2693.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "cv2.imshow(\"Frame\", img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6557fbd-1119-4e92-b1e2-562e92215159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to read image\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img_path = \"2693.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Unable to read image\")\n",
    "else:\n",
    "    print(\"Image read successfully\")\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2ac3933-5a3a-4725-9a59-9d2aafebf657",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2693.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img_path = \"2693.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "cv2.imshow(\"Frame\", img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d39dad8-d0f4-4d99-943b-a6d6082e01ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2693.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_path = \"2693.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "if img is not None:\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: Unable to read image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56b1bdb5-219f-4263-b9d4-213bfddbcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory where your images are located\n",
    "image_dir = \"C:/Users/Lenovo/OneDrive/Desktop/fashionrecm/data/Apparel/Boys/Images/\"\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir(image_dir)\n",
    "\n",
    "# Now you can work with images using relative paths\n",
    "img_path = \"2693.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f40c439-485d-4631-b806-d004d6c21696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: 2693.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Specify the directory where your images are located\n",
    "image_dir = \"C:/Users/Lenovo/OneDrive/Desktop/fashionrecm/data/Apparel/Boys/Images/\"\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir(image_dir)\n",
    "\n",
    "# Load and display an image\n",
    "img_filename = \"2693.jpg\"\n",
    "img = cv2.imread(img_filename)\n",
    "\n",
    "if img is not None:\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error loading image:\", img_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fee83eab-a68e-4edb-9740-d2e5b261e659",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2693.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image using PIL\u001b[39;00m\n\u001b[0;32m      5\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Lenovo/OneDrive/Desktop/fashionrecm/data/Apparel/Boys/Images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the PIL image to a NumPy array for use with cv2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m img_cv2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(np\u001b[38;5;241m.\u001b[39marray(img), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2693.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "image_dir = \"C:/Users/Lenovo/OneDrive/Desktop/fashionrecm/data/Apparel/Boys/Images/\"\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Convert the PIL image to a NumPy array for use with cv2\n",
    "img_cv2 = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the image using cv2\n",
    "cv2.imshow(\"Frame\", img_cv2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5a02945-e4a7-44b5-b280-60905a54ce36",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2693.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"2693.jpg\")\n",
    "cv2.imshow(\"Frame\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a56a6188-3bec-40e6-af78-24cfca2e301b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2693.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2693.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m img\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2693.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"2693.jpg\")\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df7e3784-195f-4fca-bda6-81cfbd00491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"C:\\Python311\\Scripts/2693.jpg\")\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c71a3c9-199f-4901-9bc0-cf74b7c140ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "img_path = \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "display(Image(filename=img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fecb6f40-1f9f-465c-a6c4-61ec41ce15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed030490-b542-4506-9147-27d1a46cf4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 540, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=np.array(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3e0c662-b074-42cd-b17c-439969297eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de423e3-fb26-4251-8844-9d80b0ce42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(number_of_image, 720, 540, 3)\n",
    "expand_img=np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c260e206",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expand_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexpand_img\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'expand_img' is not defined"
     ]
    }
   ],
   "source": [
    "expand_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64eafd47-64c4-43cb-8c54-1196d5ba4976",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m expand_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m720\u001b[39m,\u001b[38;5;241m540\u001b[39m ))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Now you can access the shape attribute\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexpand_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "img = Image.open(img_path)\n",
    "expand_img = img.resize((720,540 ))\n",
    "\n",
    "# Now you can access the shape attribute\n",
    "print(expand_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88ba81d4-cf14-46a8-ab95-dc2258a6e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 720\n",
      "Height: 540\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path =  \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "img = Image.open(img_path)\n",
    "expand_img = img.resize((720, 540))\n",
    "\n",
    "# Get the dimensions (width and height) of the resized image\n",
    "width, height = expand_img.size\n",
    "print(\"Width:\", width)\n",
    "print(\"Height:\", height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85a27396-654b-4795-8c07-cf12dba617f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Image' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pre_img\u001b[38;5;241m=\u001b[39m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpand_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:611\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.resnet50.preprocess_input\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.resnet.preprocess_input\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    609\u001b[0m )\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_input\u001b[39m(x, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcaffe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:124\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _preprocess_numpy_input(x, data_format\u001b[38;5;241m=\u001b[39mdata_format, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_preprocess_symbolic_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:288\u001b[0m, in \u001b[0;36m_preprocess_symbolic_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    285\u001b[0m         x \u001b[38;5;241m=\u001b[39m x[:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# 'RGB'->'BGR'\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    289\u001b[0m mean \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m103.939\u001b[39m, \u001b[38;5;241m116.779\u001b[39m, \u001b[38;5;241m123.68\u001b[39m]\n\u001b[0;32m    290\u001b[0m std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Image' object is not subscriptable"
     ]
    }
   ],
   "source": [
    " pre_img=preprocess_input(expand_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44bb6e8f-5faf-4320-ad78-a4180c91f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "img = Image.open(img_path)\n",
    "expand_img = img.resize((720, 540))\n",
    "\n",
    "# Convert the PIL image to a NumPy array\n",
    "img_array = np.array(expand_img)\n",
    "\n",
    "# Preprocess the NumPy array using Keras preprocess_input\n",
    "preprocessed_img = preprocess_input(img_array)\n",
    "\n",
    "# Now you can use the preprocessed_img in your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca25a245-0936-4e3b-bc64-22d819c2e6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image using PIL\n",
    "img = Image.open( \"C:\\Python311\\Scripts/2693.jpg\")\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "img_array = np.asarray(img)\n",
    "\n",
    "# Print the array\n",
    "print(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23d142f7-97fe-4c27-8d05-5bf2c28f1392",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpre_img\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pre_img' is not defined"
     ]
    }
   ],
   "source": [
    "pre_img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d6deb94-8c22-4fa3-ac9d-45cf3095cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "img = Image.open(img_path)\n",
    "img = img.resize((720, 540))  # Resize the image\n",
    "\n",
    "# Convert PIL Image to NumPy array\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Preprocess the image array\n",
    "pre_img = preprocess_input(img_array)\n",
    "\n",
    "# Now you can use pre_img for further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ee0abfb-a23a-41c3-91eb-640ad82dd330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "       [[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "       [[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "       [[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]],\n",
       "\n",
       "       [[151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        ...,\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ],\n",
       "        [151.061  , 138.22101, 131.32   ]]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db6dc081-9906-46ea-9e01-421a0f3fc8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 720, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51697be4-be34-4122-b54e-a03f284499cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 720, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m result\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezoyh2mvw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(pre_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3f7ebba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 720, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezoyh2mvw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(pre_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "432e8db3-1904-459c-8ca0-08db3df4e90f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16ed0740-cf6e-4b79-bc84-46c00be8c8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "img = Image.open(img_path)\n",
    "img = img.resize((224, 224))  # Resize the image\n",
    "\n",
    "# Convert PIL Image to NumPy array\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Preprocess the image array\n",
    "pre_img = preprocess_input(img_array)\n",
    "\n",
    "# Predict using the model\n",
    "result = model.predict(np.expand_dims(pre_img, axis=0))\n",
    "\n",
    "# Now you can use the result for further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e419d0f-b0ce-493a-9f2c-31b1aaec22e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9701a43e-f0ce-4abe-96e8-d45ad34ff620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet data\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the image using PIL\n",
    "img_path = \"C:\\Python311\\Scripts/2693.jpg\"\n",
    "img = Image.open(img_path)\n",
    "img = img.resize((224, 224))  # Resize the image\n",
    "\n",
    "# Convert PIL Image to NumPy array\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Preprocess the image array\n",
    "pre_img = preprocess_input(img_array)\n",
    "\n",
    "# Predict using the model and flatten the result\n",
    "result = model.predict(np.expand_dims(pre_img, axis=0)).flatten()\n",
    "\n",
    "# Now you can use the flattened result for further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1100958c-2801-4858-b38e-7d3d7adf8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized=result/norm(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c10ff0b-1912-46e8-91a3-40ea30295651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47cc0fb0-e435-460b-b025-ba72f784c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(img_path, model):\n",
    "    img=cv2.imread(img_path)\n",
    "    img=cv2.resize(img, (720, 540))\n",
    "    img=np.array(img)\n",
    "    expand_img=np.expand_dims(img,axis=0)\n",
    "    pre_img=preprocess_input(expand_img)\n",
    "    result=model.predict(pre_img),flatten()\n",
    "    normalized=result/norm(result)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3eb40bc8-b2c2-4e60-aa82-45bab97d03d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2693.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[85], line 3\u001b[0m, in \u001b[0;36mextract_feature\u001b[1;34m(img_path, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_feature\u001b[39m(img_path, model):\n\u001b[0;32m      2\u001b[0m     img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 3\u001b[0m     img\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m720\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m540\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     img\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m      5\u001b[0m     expand_img\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexpand_dims(img,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "extract_feature(\"2693.jpg\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93de4560-ae9f-4861-90a8-ffda65daba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Feature vector shape: (1000,)\n",
      "Normalized feature vector: [1.34192328e-06 3.29530394e-08 2.40140015e-08 1.68536607e-09\n",
      " 8.74160946e-07 8.75684520e-07 1.01408011e-08 4.16390478e-09\n",
      " 1.87073956e-09 1.82075954e-08 5.33130429e-09 9.89038984e-09\n",
      " 4.33959757e-09 5.98873040e-09 8.49843573e-08 6.03730044e-09\n",
      " 1.64955594e-07 8.72406147e-09 1.30892674e-09 1.38491254e-08\n",
      " 4.36691527e-09 3.62011470e-08 1.82102013e-08 3.46316975e-09\n",
      " 1.78163404e-08 5.76171155e-09 3.17695292e-09 9.25778565e-08\n",
      " 9.35964479e-08 4.26778779e-10 3.77118514e-09 1.57564592e-08\n",
      " 1.44968002e-08 1.52308139e-08 2.80328880e-08 7.26880001e-10\n",
      " 4.20516990e-08 1.26139579e-08 7.81872558e-08 1.85265225e-08\n",
      " 9.23184285e-09 1.91734788e-08 2.07349533e-08 5.73191130e-08\n",
      " 1.54745585e-08 6.58636310e-08 2.87091115e-08 7.02890190e-08\n",
      " 2.06493489e-08 4.53301574e-09 1.79960900e-08 1.78751782e-06\n",
      " 1.52824455e-07 4.17865706e-08 6.61215127e-09 2.44917935e-08\n",
      " 2.04867301e-09 2.84843384e-08 6.56112391e-08 7.17847968e-08\n",
      " 5.09516092e-08 8.85330209e-09 1.01721840e-08 8.64961791e-09\n",
      " 1.17935048e-08 7.78250298e-10 4.93012671e-08 3.79444849e-08\n",
      " 1.21476500e-08 5.70057637e-08 6.99347424e-09 3.63133914e-08\n",
      " 2.14223772e-09 1.19141923e-08 4.06421430e-09 1.22079541e-07\n",
      " 3.25199601e-08 2.53209054e-09 7.29930250e-08 4.80617501e-08\n",
      " 2.38754367e-08 1.19409922e-08 2.21907346e-08 4.52529303e-09\n",
      " 2.57491417e-10 1.57401487e-08 1.67247141e-08 4.54889388e-08\n",
      " 3.79682518e-07 2.59511221e-08 9.51238377e-09 8.32216429e-08\n",
      " 6.59177646e-09 4.26025082e-09 6.27125285e-09 8.82718432e-09\n",
      " 1.26837056e-08 2.01057393e-09 2.77207124e-09 3.35671491e-09\n",
      " 1.93299687e-09 8.69647522e-07 6.74354128e-09 7.58586225e-08\n",
      " 4.86126162e-08 2.21855281e-08 3.86390553e-07 7.44445705e-09\n",
      " 5.13915710e-09 1.40093279e-08 5.47080992e-10 4.93574390e-08\n",
      " 2.15527169e-08 3.04900638e-08 3.22208082e-09 2.31396613e-09\n",
      " 6.66412148e-10 1.39563348e-08 1.70158660e-06 4.23544435e-08\n",
      " 2.01224370e-08 3.81640689e-07 2.80413502e-07 2.29673020e-07\n",
      " 2.91056068e-07 3.09357784e-09 9.89280480e-09 6.92508806e-09\n",
      " 7.92160226e-10 3.12505688e-09 3.59100971e-09 4.54820626e-09\n",
      " 4.48900606e-09 3.53071372e-09 1.30576994e-09 3.60974362e-09\n",
      " 8.83264129e-09 9.38878397e-09 1.14972156e-08 1.18212218e-09\n",
      " 8.10702949e-10 2.46091876e-08 9.83772508e-10 5.42659571e-08\n",
      " 3.78614740e-09 9.91952120e-09 2.69470735e-09 7.24057481e-09\n",
      " 2.24848695e-09 1.04499804e-08 5.30220001e-09 9.43831424e-07\n",
      " 5.38911209e-08 8.29838882e-06 6.67317153e-08 1.12728678e-07\n",
      " 2.87506481e-08 1.08056483e-07 3.01106020e-08 4.65445886e-08\n",
      " 4.95004826e-07 1.23439509e-06 7.87880126e-08 2.12760696e-07\n",
      " 3.99141129e-08 9.61123661e-08 2.18642473e-08 2.75103567e-08\n",
      " 4.83232895e-07 7.25138307e-07 1.04947151e-06 2.19984116e-07\n",
      " 1.15982255e-06 4.98101883e-07 2.64030646e-08 8.74077131e-08\n",
      " 1.20617358e-07 3.18273891e-07 2.25835424e-06 1.30999837e-07\n",
      " 5.43418821e-08 4.83646652e-08 3.84057330e-07 3.88427952e-06\n",
      " 3.04286431e-07 3.55252581e-07 1.23947927e-06 8.92744765e-07\n",
      " 2.34483608e-07 3.62705606e-07 7.34727166e-07 5.98505380e-07\n",
      " 1.45279330e-07 1.32007335e-06 1.78031186e-07 3.92147058e-06\n",
      " 2.59355829e-06 1.89559657e-07 2.40294128e-07 7.38499966e-06\n",
      " 7.75348639e-08 6.95718597e-07 3.93227856e-06 2.79670144e-06\n",
      " 9.97750135e-07 7.30823260e-08 2.00092654e-08 3.46030419e-07\n",
      " 2.40380047e-07 4.22365822e-08 2.34055989e-07 1.00733246e-07\n",
      " 5.46693535e-08 3.48000313e-08 1.67623895e-07 1.00552711e-07\n",
      " 5.73484556e-07 7.14057151e-08 3.28434133e-08 5.33212159e-08\n",
      " 8.79602808e-08 2.40727935e-08 1.61142225e-07 2.99934527e-07\n",
      " 1.16374075e-07 3.12453579e-07 3.93781328e-08 5.19724992e-08\n",
      " 3.19929711e-07 6.56984184e-07 4.20159409e-08 4.56982576e-08\n",
      " 1.39343712e-07 1.22204722e-06 2.45811719e-07 4.16761168e-07\n",
      " 1.24185931e-07 1.15519889e-07 1.72822183e-07 2.67992561e-07\n",
      " 1.68814083e-07 2.90916038e-08 1.98171950e-08 1.24571557e-07\n",
      " 8.01616107e-09 1.10161004e-07 9.14948828e-09 6.90195236e-07\n",
      " 4.22503597e-08 7.74660919e-07 4.11557068e-07 8.63742216e-08\n",
      " 2.07600735e-07 2.32561774e-08 8.38803260e-07 7.46466569e-08\n",
      " 5.84759277e-07 1.46357843e-06 3.78795704e-07 1.32014134e-06\n",
      " 2.29049942e-06 4.91632534e-07 1.55413574e-07 1.72355229e-07\n",
      " 1.17955580e-07 1.60935201e-07 2.41988865e-08 4.14852721e-08\n",
      " 8.37539815e-08 2.12524057e-07 3.21148178e-07 2.00369534e-08\n",
      " 1.33659398e-07 2.07354685e-08 5.39849445e-08 1.76095138e-08\n",
      " 4.60260239e-08 7.23344300e-08 3.61597974e-09 2.44072940e-08\n",
      " 1.84702571e-07 1.92231346e-06 3.06236387e-07 2.43751947e-06\n",
      " 4.31786908e-08 6.82194212e-08 2.38247164e-08 7.56522880e-08\n",
      " 5.84176174e-09 1.77577171e-08 3.45630013e-09 1.03687174e-08\n",
      " 2.12485332e-07 7.20869267e-08 1.63987963e-07 2.59646498e-07\n",
      " 6.83777625e-06 1.87431638e-07 3.89874231e-08 4.17080592e-08\n",
      " 1.07602709e-08 3.17224398e-08 2.13465636e-08 2.28364812e-08\n",
      " 3.15032018e-08 1.54765960e-08 4.47089334e-08 2.73436349e-08\n",
      " 2.67942095e-08 5.60449198e-09 2.27369242e-07 2.04941175e-09\n",
      " 1.87814830e-08 4.12972199e-08 6.91578563e-08 1.15976260e-08\n",
      " 3.77587117e-09 1.20778081e-08 1.07601892e-08 5.33574287e-08\n",
      " 1.39100669e-08 1.65964531e-09 9.11510423e-09 4.98694552e-09\n",
      " 6.70896627e-09 8.01095297e-08 2.03433204e-09 8.34235209e-07\n",
      " 1.76250055e-08 1.55996780e-08 2.81807843e-07 1.01748192e-07\n",
      " 1.65722540e-07 9.24034396e-07 3.81872773e-08 3.20085789e-08\n",
      " 1.17057448e-08 3.93487767e-08 1.42706796e-07 1.60581912e-08\n",
      " 2.69525895e-08 2.84942132e-07 5.90931819e-08 3.87248456e-08\n",
      " 1.17547941e-07 1.75540809e-08 2.55852619e-08 9.00283368e-08\n",
      " 5.13333820e-09 4.35927561e-09 1.25777522e-08 5.81203130e-09\n",
      " 1.42832128e-08 5.79015680e-09 2.01855272e-07 9.21497687e-08\n",
      " 3.75763136e-08 3.73117039e-08 1.88088435e-07 9.68080016e-08\n",
      " 2.24493988e-08 4.20396475e-07 4.31384350e-08 1.82656592e-07\n",
      " 7.84371537e-08 9.26882890e-08 5.96279150e-08 5.18259696e-07\n",
      " 2.09561737e-08 1.90555003e-08 1.86093949e-08 1.87246467e-08\n",
      " 2.46290011e-08 3.91703345e-08 1.77174153e-09 1.24762769e-08\n",
      " 1.83781772e-08 2.31536266e-08 4.34200054e-08 1.09384963e-07\n",
      " 9.11071183e-08 1.51926312e-08 1.66946180e-07 3.01315133e-08\n",
      " 8.91601992e-09 2.90865984e-07 4.25302709e-08 2.96384473e-09\n",
      " 1.19060370e-08 2.45806805e-05 5.61755931e-09 4.20606466e-06\n",
      " 1.28098563e-07 4.00444122e-09 5.88336206e-06 2.96304370e-06\n",
      " 2.10264801e-08 1.15852012e-08 2.10160664e-07 3.26625159e-05\n",
      " 3.04074820e-06 2.66789080e-08 4.27691909e-08 1.45037347e-07\n",
      " 2.27437091e-09 1.47766066e-08 7.76816975e-08 1.54762142e-06\n",
      " 3.79602483e-09 5.49860374e-07 1.69356458e-08 1.17514108e-03\n",
      " 1.76316121e-06 6.92638878e-07 1.45742479e-06 8.08352212e-08\n",
      " 4.18632567e-07 1.56636531e-07 1.30423621e-06 4.48199135e-05\n",
      " 8.21711623e-08 6.63666322e-09 8.26706525e-07 4.40335057e-08\n",
      " 5.01531350e-09 2.35427944e-08 1.00308432e-06 1.10842677e-06\n",
      " 2.93286831e-07 3.08579644e-07 3.83429693e-07 4.75886736e-05\n",
      " 7.08547603e-08 1.57150425e-04 3.03589641e-05 6.75882984e-06\n",
      " 6.90454343e-08 9.68598535e-09 2.95498040e-07 1.11319923e-06\n",
      " 1.25698616e-08 8.66856524e-08 3.97377136e-07 2.59318131e-05\n",
      " 3.69748427e-08 2.22784593e-06 2.68135091e-06 7.38289464e-06\n",
      " 5.48022854e-07 2.74498002e-09 5.03748190e-08 2.95491247e-07\n",
      " 1.57627055e-05 1.48612372e-07 1.28949509e-08 1.85935001e-08\n",
      " 7.18101364e-06 1.25705174e-05 3.60745958e-08 9.52886967e-06\n",
      " 6.01605787e-09 8.67033918e-07 5.42165571e-06 3.15354237e-06\n",
      " 4.38229972e-06 3.29069234e-03 1.46482515e-08 1.20814676e-07\n",
      " 3.15022186e-09 2.17682839e-07 7.26980886e-07 1.41177248e-08\n",
      " 8.28987368e-09 3.88659402e-07 1.53746456e-03 7.99205502e-09\n",
      " 2.35859288e-09 1.03927214e-05 4.37911194e-06 1.24846808e-08\n",
      " 1.12850230e-07 1.04709409e-06 6.39807809e-07 3.59153707e-09\n",
      " 7.29874614e-08 8.55382538e-08 6.81749013e-09 1.06768972e-07\n",
      " 6.80951757e-07 5.13974854e-08 5.13331179e-06 1.60037644e-06\n",
      " 1.86297186e-07 3.54287799e-08 3.40430915e-07 3.92407777e-08\n",
      " 1.65131709e-07 1.05578861e-08 7.84975818e-09 1.41080554e-05\n",
      " 2.68217679e-08 3.10254995e-06 1.13742203e-06 1.45857683e-07\n",
      " 1.49013374e-06 9.42274951e-08 1.36856293e-09 3.77999243e-07\n",
      " 3.21402013e-06 1.35325493e-07 4.67694683e-08 2.08851869e-08\n",
      " 1.87443632e-07 2.13434919e-06 1.75630632e-07 8.11090047e-07\n",
      " 1.46829052e-05 5.48979585e-07 8.64333572e-07 6.92501487e-07\n",
      " 2.53210546e-05 3.75976214e-07 1.58302919e-06 2.40559962e-06\n",
      " 4.10937992e-06 4.74410626e-08 1.53715416e-06 1.01813612e-07\n",
      " 1.51746249e-07 4.17544506e-03 6.41869860e-07 7.92543347e-08\n",
      " 1.36368399e-07 6.02841794e-07 7.72608303e-07 8.08382605e-09\n",
      " 5.12302822e-09 1.17897777e-07 5.61200437e-08 6.33278705e-06\n",
      " 2.26328211e-07 5.08835058e-07 2.35396533e-06 2.34723466e-05\n",
      " 4.13387369e-07 6.39050427e-07 1.51086624e-07 4.65097783e-09\n",
      " 1.06938224e-07 8.98702256e-03 1.79574386e-07 2.20905872e-06\n",
      " 4.78529500e-07 1.79332034e-07 1.14626637e-08 1.38880978e-07\n",
      " 4.66247378e-08 4.61131958e-06 1.32455440e-07 1.25002782e-06\n",
      " 1.00072521e-06 3.23539211e-07 4.12452517e-09 5.68831453e-08\n",
      " 2.32037589e-08 1.46746508e-08 1.14837874e-07 7.04318381e-07\n",
      " 3.64828775e-05 9.61474370e-07 1.08661799e-04 1.01027107e-08\n",
      " 2.43047200e-08 1.69737095e-08 9.21945897e-08 2.51537902e-08\n",
      " 6.20204277e-10 1.86974012e-06 1.75301750e-06 4.19411395e-09\n",
      " 2.40747671e-08 1.88224658e-09 1.38547080e-07 4.99726241e-07\n",
      " 4.36336677e-06 1.01457454e-06 3.35814661e-07 1.19290826e-05\n",
      " 4.43043420e-04 1.04671526e-05 6.92366825e-07 5.09588317e-05\n",
      " 8.02698210e-08 4.23377060e-07 2.52532022e-08 1.76957840e-07\n",
      " 1.16036417e-05 1.10759793e-05 8.08951839e-09 1.10732060e-06\n",
      " 3.26965164e-05 5.32358740e-07 5.12878216e-07 3.56555252e-09\n",
      " 5.57457014e-08 1.68156106e-07 3.30520857e-06 1.18390096e-06\n",
      " 1.30894699e-03 7.29517868e-09 8.50972354e-01 4.34505819e-06\n",
      " 1.95787621e-07 3.20142448e-07 4.55347996e-04 8.55519320e-05\n",
      " 2.14157922e-06 1.68271072e-04 7.40968389e-08 4.18091339e-08\n",
      " 6.88378236e-07 5.15805390e-08 1.30927594e-06 3.58618627e-06\n",
      " 3.09314885e-08 6.65321878e-08 8.92427607e-08 2.31263408e-09\n",
      " 2.51565613e-09 1.25083204e-07 6.91413717e-08 4.42015704e-07\n",
      " 6.54862049e-08 1.17501095e-07 4.69710404e-09 1.21324842e-06\n",
      " 2.17017587e-04 6.58668924e-08 2.30826382e-02 2.26114407e-05\n",
      " 7.90482257e-09 3.91984440e-06 1.74311015e-06 2.39723136e-06\n",
      " 8.07165446e-09 2.69137912e-09 4.90405405e-08 3.57026181e-07\n",
      " 3.24030793e-07 1.99221247e-07 1.78263349e-06 1.80361064e-06\n",
      " 5.14238382e-05 4.09975769e-08 3.24210370e-09 9.04189510e-05\n",
      " 3.63634314e-08 4.79878288e-08 3.78239492e-05 1.11127508e-06\n",
      " 2.35507418e-08 9.09601394e-10 1.13275483e-07 3.74680269e-08\n",
      " 1.68135898e-07 8.92750673e-09 6.30025568e-07 1.02284594e-06\n",
      " 9.95086413e-09 4.11403647e-07 2.17596896e-09 1.36619121e-07\n",
      " 1.52576217e-06 9.05655668e-07 3.16250816e-06 1.15791558e-07\n",
      " 1.41171131e-05 3.57587396e-07 8.75825299e-06 2.48000845e-07\n",
      " 7.60191870e-06 2.18634773e-06 2.99782243e-08 1.51581375e-07\n",
      " 2.93454809e-06 1.88596938e-09 5.31943343e-08 1.21181609e-09\n",
      " 5.02548314e-09 2.86747593e-07 1.69234005e-09 3.13987016e-06\n",
      " 3.36040219e-04 1.10311348e-07 1.54443942e-08 2.32147286e-07\n",
      " 1.66716782e-05 2.19466873e-02 4.76297091e-09 6.71720557e-07\n",
      " 2.66398692e-05 1.55787143e-06 2.12681172e-07 2.61730708e-08\n",
      " 3.53715244e-08 5.92183580e-10 2.89399651e-08 1.26460211e-08\n",
      " 8.11570118e-08 4.37838753e-05 2.67684891e-06 8.17453952e-07\n",
      " 2.31393130e-07 5.82557595e-06 6.42496957e-07 2.33492506e-06\n",
      " 1.50761053e-07 4.94349539e-09 2.04225543e-07 8.77876062e-07\n",
      " 8.13170459e-07 2.05716537e-06 2.76652668e-06 8.35527487e-07\n",
      " 1.11857275e-07 1.83679873e-07 6.30975592e-07 4.58309168e-09\n",
      " 1.46635721e-04 6.70573286e-08 4.51102373e-08 1.34813226e-05\n",
      " 7.89207036e-07 1.29820208e-07 3.81225078e-08 1.23868464e-03\n",
      " 8.40670253e-08 1.56707127e-08 9.14394533e-08 2.96230496e-07\n",
      " 3.65938058e-06 1.86944567e-06 2.04026878e-06 4.04258941e-07\n",
      " 3.42356223e-08 5.38706750e-08 1.81411878e-07 1.70061480e-06\n",
      " 6.35756078e-06 3.01863906e-06 5.46875572e-06 2.05669615e-08\n",
      " 3.96379420e-07 3.91032336e-06 1.56154538e-08 8.79171402e-09\n",
      " 9.77049908e-08 4.28345004e-08 3.61617282e-07 1.24994062e-06\n",
      " 1.64320645e-05 2.09348329e-07 8.81008120e-08 1.76352285e-06\n",
      " 1.77834518e-05 8.03254579e-07 1.37899704e-07 5.84345071e-05\n",
      " 2.57501966e-08 6.48447394e-06 5.88608032e-07 9.07570836e-07\n",
      " 3.70137786e-05 3.48941654e-07 3.62674797e-07 6.59539592e-06\n",
      " 4.36324171e-06 7.66294704e-07 5.90033642e-06 6.67049660e-09\n",
      " 3.10541395e-07 5.13168636e-08 1.57096096e-07 6.29391650e-08\n",
      " 1.98130215e-06 3.77524088e-07 4.91583819e-07 3.14025783e-07\n",
      " 1.23359110e-08 1.88301760e-06 6.45307318e-06 1.55576470e-06\n",
      " 9.61976039e-05 6.01458247e-04 1.31284996e-05 3.11839290e-06\n",
      " 1.24660510e-04 5.04937442e-03 1.48034485e-06 7.69973553e-07\n",
      " 6.82059831e-09 1.23828136e-06 2.78891594e-08 5.98936481e-07\n",
      " 2.88458267e-07 1.83752331e-06 4.06130675e-06 1.94017833e-08\n",
      " 3.37605024e-06 3.24169100e-08 1.65889830e-07 9.16208023e-07\n",
      " 5.22623687e-08 1.56027363e-05 3.96819644e-09 8.21158253e-09\n",
      " 6.48561169e-08 3.53264684e-09 1.78455139e-07 2.82096096e-07\n",
      " 8.73920047e-09 6.17877438e-09 1.82351403e-06 6.10607676e-04\n",
      " 2.00301074e-05 4.37223449e-08 5.31894386e-07 2.12229764e-07\n",
      " 1.85180033e-05 5.74281867e-09 1.10930683e-04 3.73529531e-07\n",
      " 1.41480839e-07 3.51360963e-09 3.15908096e-06 2.10634106e-08\n",
      " 9.54671918e-07 1.21592939e-05 1.63732238e-06 4.59818672e-09\n",
      " 3.96386640e-05 5.24077356e-01 5.48722083e-03 4.72189004e-06\n",
      " 4.07150583e-06 8.03862974e-07 3.93241670e-08 3.13942081e-08\n",
      " 5.62398725e-07 2.39658789e-07 2.59414101e-05 1.32476416e-07\n",
      " 3.78668756e-06 1.93014529e-07 2.32253797e-07 1.29115136e-08\n",
      " 1.29902688e-07 3.17744366e-07 3.76839679e-08 1.24221879e-06\n",
      " 3.79501337e-08 4.28815667e-07 2.87428520e-05 8.49952286e-08\n",
      " 1.38032652e-08 2.20792643e-07 2.51089229e-08 2.06176676e-08\n",
      " 4.06590459e-07 2.46162788e-04 5.53873406e-07 7.19983007e-08\n",
      " 3.55789484e-06 1.12283509e-07 1.39724143e-09 4.18479289e-07\n",
      " 4.81554434e-06 8.08142886e-07 2.63314988e-08 1.92802690e-06\n",
      " 4.60213528e-07 3.37809212e-08 3.29372824e-07 3.66742427e-07\n",
      " 1.21484369e-08 1.75697933e-04 5.96664904e-08 3.32720781e-04\n",
      " 6.10011863e-09 7.93039376e-08 9.68913696e-07 6.89863498e-07\n",
      " 3.06797756e-06 1.41337214e-05 1.53988258e-05 4.11646326e-08\n",
      " 4.54590406e-07 4.02429978e-05 4.71709654e-06 4.01051648e-06\n",
      " 4.23356061e-09 4.42115002e-08 1.27499297e-05 5.07357436e-06\n",
      " 2.14605578e-07 5.55648398e-07 4.66476704e-05 4.18475068e-08\n",
      " 5.48433210e-09 2.22750373e-06 2.37060476e-06 1.06837018e-03\n",
      " 3.54218201e-08 1.15001333e-08 9.24477650e-09 4.59068133e-07\n",
      " 2.03371164e-05 2.43889474e-07 3.32155459e-08 1.06182462e-07\n",
      " 5.62434899e-08 6.97197095e-07 3.36848593e-08 5.50187679e-07\n",
      " 1.16292824e-06 1.69329894e-07 4.73246544e-08 3.49933238e-08\n",
      " 2.68036501e-07 5.83174551e-06 6.08378485e-08 6.63107994e-06\n",
      " 2.08937945e-06 3.76212938e-07 1.44809371e-06 4.29155648e-07\n",
      " 1.70141206e-07 3.10858559e-06 1.26219129e-06 2.87545140e-06\n",
      " 8.01639359e-08 1.76255757e-08 4.24572647e-07 1.09690473e-06\n",
      " 1.71187409e-07 4.23580779e-08 7.49552154e-09 8.71667627e-09\n",
      " 1.73066871e-06 3.97199997e-08 3.02608584e-07 1.01727714e-07\n",
      " 3.52848701e-08 7.43906767e-08 8.37859034e-07 2.65071492e-07\n",
      " 7.02532290e-08 7.10423222e-08 6.23291783e-08 1.04507734e-07\n",
      " 1.06004791e-07 5.12884844e-06 6.81596248e-07 3.91799730e-08\n",
      " 8.35929200e-07 5.65757716e-07 3.00675765e-07 9.01405386e-08\n",
      " 5.85563953e-07 2.89669600e-07 8.58142641e-08 2.85677601e-07\n",
      " 8.71939108e-08 1.22903270e-08 3.46664102e-08 7.08186532e-09\n",
      " 2.71438205e-09 1.48789084e-07 5.11509541e-07 1.73730808e-08\n",
      " 6.21509599e-09 1.88303386e-06 6.42616200e-08 5.49637447e-09\n",
      " 1.55195630e-06 1.43185908e-08 1.18690515e-07 8.50897607e-07\n",
      " 1.02342511e-07 8.51940456e-08 3.25202123e-08 3.75255160e-09\n",
      " 2.17487042e-08 6.09344397e-09 1.72381043e-09 6.88081014e-09\n",
      " 7.72763098e-09 8.52099369e-09 9.15728009e-08 2.09101404e-06]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications import ResNet50\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def extract_feature(img_path, model):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img)\n",
    "    expand_img = np.expand_dims(img, axis=0)\n",
    "    pre_img = preprocess_input(expand_img)\n",
    "    result = model.predict(pre_img).flatten()\n",
    "    normalized = result / norm(result)\n",
    "    return normalized\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet data\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Example usage\n",
    "feature_vector = extract_feature(\"C:\\Python311\\Scripts/2693.jpg\", model)\n",
    "\n",
    "print(\"Feature vector shape:\", feature_vector.shape)\n",
    "print(\"Normalized feature vector:\", feature_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a4ec7fa7-cc82-4a0d-9644-d5b34a330527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bba4baa8-0c9b-4e8d-bd7c-95ad9b05518a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m filename\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      2\u001b[0m feature_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m     filename\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,file))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data'"
     ]
    }
   ],
   "source": [
    "filename=[]\n",
    "feature_list=[]\n",
    "\n",
    "for file in os.listdir('data'):\n",
    "    filename.append(os.path.join('data',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a1c0897-c875-493a-8a82-1738f942e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_directory = r'C:\\Users\\Lenovo\\OneDrive\\Desktop\\fashionrecm\\dataset'  # Replace with the actual path\n",
    "filename = []\n",
    "feature_list = []\n",
    "\n",
    "for file in os.listdir(data_directory):\n",
    "    filename.append(os.path.join(data_directory, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f81a622-ac5b-4bee-b7c2-87487231eb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\dataset\\\\10054.jpg',\n",
       " 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\dataset\\\\10649.jpg',\n",
       " 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\dataset\\\\10671.jpg',\n",
       " 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\dataset\\\\12840.jpg',\n",
       " 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\fashionrecm\\\\dataset\\\\12844.jpg']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f5552d2-755f-49a2-91b0-e4d6516766cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/759 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 326ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/759 [00:00<08:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 267ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/759 [00:01<06:18,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 271ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/759 [00:01<06:33,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 242ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/759 [00:01<05:48,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/759 [00:02<05:22,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 279ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/759 [00:02<05:51,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 273ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/759 [00:03<05:56,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 255ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/759 [00:03<05:59,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/759 [00:04<06:03,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 259ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 10/759 [00:04<05:43,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 294ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 11/759 [00:05<05:57,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 260ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 12/759 [00:05<06:07,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 247ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 13/759 [00:06<06:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 262ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 14/759 [00:06<06:11,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 291ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 15/759 [00:07<06:20,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 16/759 [00:07<06:13,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 17/759 [00:08<06:11,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 18/759 [00:08<06:14,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 19/759 [00:09<06:17,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 228ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 20/759 [00:09<06:06,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 261ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 21/759 [00:10<06:05,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 280ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 22/759 [00:10<06:12,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 23/759 [00:11<05:59,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 248ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 24/759 [00:11<05:48,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 295ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 25/759 [00:12<05:57,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 282ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 26/759 [00:12<06:10,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 251ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 27/759 [00:13<06:14,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 260ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 28/759 [00:13<06:08,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 274ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 29/759 [00:14<06:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 286ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 30/759 [00:14<06:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 31/759 [00:15<06:09,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 32/759 [00:15<06:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 251ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 33/759 [00:16<05:31,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 34/759 [00:16<05:44,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 35/759 [00:17<05:49,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 36/759 [00:17<05:49,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 326ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 37/759 [00:18<06:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 260ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 38/759 [00:18<05:41,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 253ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 39/759 [00:18<05:22,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 264ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 40/759 [00:19<05:06,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 260ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 41/759 [00:19<05:48,  2.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(filename):\n\u001b[1;32m----> 4\u001b[0m     feature_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextract_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[89], line 13\u001b[0m, in \u001b[0;36mextract_feature\u001b[1;34m(img_path, model)\u001b[0m\n\u001b[0;32m     11\u001b[0m expand_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m pre_img \u001b[38;5;241m=\u001b[39m preprocess_input(expand_img)\n\u001b[1;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_img\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     14\u001b[0m normalized \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m/\u001b[39m norm(result)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normalized\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2521\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2512\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2513\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2515\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2519\u001b[0m         )\n\u001b[1;32m-> 2521\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2525\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2534\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1678\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1676\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1285\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1284\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:353\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 353\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2323\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[1;32m-> 2323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[1;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:42\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure\u001b[38;5;241m.\u001b[39m_element_spec\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m---> 42\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:2387\u001b[0m, in \u001b[0;36mflat_map_dataset\u001b[1;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   2385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   2386\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2387\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2388\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFlatMapDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2389\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2390\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   2392\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "for file in tqdm(filename):\n",
    "    feature_list.append(extract_feature(file,model))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4c821ab-b0c3-419a-94dd-056d5f97e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(feature_list,open('featurevector.pkl','wb'))\n",
    "pickle.dump(filename,open('filename.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d12138-b5ab-4484-b0d4-5c4cf76964e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
